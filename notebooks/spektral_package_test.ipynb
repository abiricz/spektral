{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from spektral.datasets import citation\n",
    "import spektral\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spektral.layers import GraphConv\n",
    "from spektral import utils\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source:\n",
    "https://danielegrattarola.github.io/spektral/getting-started/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n",
      "Pre-processing node features\n"
     ]
    }
   ],
   "source": [
    "data = spektral.datasets.citation.load_data('cora')\n",
    "A, X, y_train, y_val, y_test, train_mask, val_mask, test_mask = data\n",
    "\n",
    "N = A.shape[0]\n",
    "F = X.shape[-1]\n",
    "n_classes = y_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2708, 2708), (2708, 1433), (2708, 7), (2708, 7), (2708,), (2708,), (2708,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, X.shape, y_val.shape, y_test.shape, train_mask.shape, val_mask.shape, test_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abiricz/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/abiricz/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "X_in = Input(shape=(F, ))  # Input layer for X\n",
    "A_in = Input((N, ), sparse=True)  # Input layer for A\n",
    "\n",
    "graph_conv_1 = GraphConv(16, activation='relu')([X_in, A_in])\n",
    "dropout = Dropout(0.5)(graph_conv_1)\n",
    "graph_conv_2 = GraphConv(n_classes, activation='softmax')([dropout, A_in])\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, A_in], outputs=graph_conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = utils.localpooling_filter(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2708)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_1 (GraphConv)        (None, 16)           22944       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           graph_conv_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_2 (GraphConv)        (None, 7)            119         dropout_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,063\n",
      "Trainable params: 23,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abiricz/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2708 samples, validate on 2708 samples\n",
      "Epoch 1/100\n",
      "2708/2708 [==============================] - 1s 537us/step - loss: 1.9461 - weighted_acc: 0.1429 - val_loss: 1.9452 - val_weighted_acc: 0.1820\n",
      "Epoch 2/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.9447 - weighted_acc: 0.2500 - val_loss: 1.9449 - val_weighted_acc: 0.2260\n",
      "Epoch 3/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.9447 - weighted_acc: 0.2071 - val_loss: 1.9446 - val_weighted_acc: 0.2700\n",
      "Epoch 4/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.9440 - weighted_acc: 0.3071 - val_loss: 1.9443 - val_weighted_acc: 0.3100\n",
      "Epoch 5/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.9430 - weighted_acc: 0.3071 - val_loss: 1.9440 - val_weighted_acc: 0.3500\n",
      "Epoch 6/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.9421 - weighted_acc: 0.3929 - val_loss: 1.9436 - val_weighted_acc: 0.3840\n",
      "Epoch 7/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.9410 - weighted_acc: 0.4429 - val_loss: 1.9431 - val_weighted_acc: 0.4000\n",
      "Epoch 8/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.9403 - weighted_acc: 0.4643 - val_loss: 1.9426 - val_weighted_acc: 0.4240\n",
      "Epoch 9/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.9395 - weighted_acc: 0.5500 - val_loss: 1.9420 - val_weighted_acc: 0.4580\n",
      "Epoch 10/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9381 - weighted_acc: 0.5786 - val_loss: 1.9414 - val_weighted_acc: 0.4820\n",
      "Epoch 11/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9375 - weighted_acc: 0.5429 - val_loss: 1.9407 - val_weighted_acc: 0.4940\n",
      "Epoch 12/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9369 - weighted_acc: 0.5357 - val_loss: 1.9400 - val_weighted_acc: 0.5160\n",
      "Epoch 13/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.9341 - weighted_acc: 0.6429 - val_loss: 1.9392 - val_weighted_acc: 0.5420\n",
      "Epoch 14/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.9358 - weighted_acc: 0.5214 - val_loss: 1.9385 - val_weighted_acc: 0.5560\n",
      "Epoch 15/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9327 - weighted_acc: 0.6286 - val_loss: 1.9378 - val_weighted_acc: 0.5700\n",
      "Epoch 16/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.9313 - weighted_acc: 0.6357 - val_loss: 1.9372 - val_weighted_acc: 0.5900\n",
      "Epoch 17/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.9299 - weighted_acc: 0.6643 - val_loss: 1.9365 - val_weighted_acc: 0.5980\n",
      "Epoch 18/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9309 - weighted_acc: 0.5786 - val_loss: 1.9359 - val_weighted_acc: 0.6080\n",
      "Epoch 19/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9286 - weighted_acc: 0.6214 - val_loss: 1.9353 - val_weighted_acc: 0.6100\n",
      "Epoch 20/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.9268 - weighted_acc: 0.6714 - val_loss: 1.9347 - val_weighted_acc: 0.6200\n",
      "Epoch 21/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9270 - weighted_acc: 0.6500 - val_loss: 1.9341 - val_weighted_acc: 0.6140\n",
      "Epoch 22/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9238 - weighted_acc: 0.7286 - val_loss: 1.9335 - val_weighted_acc: 0.6140\n",
      "Epoch 23/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.9229 - weighted_acc: 0.7214 - val_loss: 1.9329 - val_weighted_acc: 0.6240\n",
      "Epoch 24/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.9206 - weighted_acc: 0.6929 - val_loss: 1.9323 - val_weighted_acc: 0.6200\n",
      "Epoch 25/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.9238 - weighted_acc: 0.6429 - val_loss: 1.9317 - val_weighted_acc: 0.6180\n",
      "Epoch 26/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9182 - weighted_acc: 0.7000 - val_loss: 1.9310 - val_weighted_acc: 0.6200\n",
      "Epoch 27/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9200 - weighted_acc: 0.7000 - val_loss: 1.9303 - val_weighted_acc: 0.6260\n",
      "Epoch 28/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9161 - weighted_acc: 0.7571 - val_loss: 1.9296 - val_weighted_acc: 0.6420\n",
      "Epoch 29/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9141 - weighted_acc: 0.7929 - val_loss: 1.9288 - val_weighted_acc: 0.6520\n",
      "Epoch 30/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.9142 - weighted_acc: 0.7714 - val_loss: 1.9280 - val_weighted_acc: 0.6560\n",
      "Epoch 31/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.9114 - weighted_acc: 0.7571 - val_loss: 1.9271 - val_weighted_acc: 0.6600\n",
      "Epoch 32/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.9120 - weighted_acc: 0.7357 - val_loss: 1.9263 - val_weighted_acc: 0.6620\n",
      "Epoch 33/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.9092 - weighted_acc: 0.7929 - val_loss: 1.9254 - val_weighted_acc: 0.6680\n",
      "Epoch 34/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9059 - weighted_acc: 0.7857 - val_loss: 1.9245 - val_weighted_acc: 0.6760\n",
      "Epoch 35/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.9059 - weighted_acc: 0.7429 - val_loss: 1.9236 - val_weighted_acc: 0.6800\n",
      "Epoch 36/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.9029 - weighted_acc: 0.8286 - val_loss: 1.9226 - val_weighted_acc: 0.6860\n",
      "Epoch 37/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.9011 - weighted_acc: 0.7929 - val_loss: 1.9217 - val_weighted_acc: 0.6880\n",
      "Epoch 38/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.9000 - weighted_acc: 0.8071 - val_loss: 1.9208 - val_weighted_acc: 0.6960\n",
      "Epoch 39/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.8984 - weighted_acc: 0.8143 - val_loss: 1.9199 - val_weighted_acc: 0.6960\n",
      "Epoch 40/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.8996 - weighted_acc: 0.7929 - val_loss: 1.9190 - val_weighted_acc: 0.7020\n",
      "Epoch 41/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.8940 - weighted_acc: 0.8143 - val_loss: 1.9181 - val_weighted_acc: 0.7040\n",
      "Epoch 42/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8934 - weighted_acc: 0.8357 - val_loss: 1.9173 - val_weighted_acc: 0.7020\n",
      "Epoch 43/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8888 - weighted_acc: 0.8143 - val_loss: 1.9164 - val_weighted_acc: 0.7020\n",
      "Epoch 44/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8892 - weighted_acc: 0.8500 - val_loss: 1.9155 - val_weighted_acc: 0.7020\n",
      "Epoch 45/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.8906 - weighted_acc: 0.8143 - val_loss: 1.9146 - val_weighted_acc: 0.7020\n",
      "Epoch 46/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.8861 - weighted_acc: 0.8286 - val_loss: 1.9137 - val_weighted_acc: 0.7020\n",
      "Epoch 47/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8861 - weighted_acc: 0.7929 - val_loss: 1.9129 - val_weighted_acc: 0.7020\n",
      "Epoch 48/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8846 - weighted_acc: 0.8143 - val_loss: 1.9120 - val_weighted_acc: 0.7020\n",
      "Epoch 49/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8791 - weighted_acc: 0.8500 - val_loss: 1.9111 - val_weighted_acc: 0.7040\n",
      "Epoch 50/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8783 - weighted_acc: 0.8500 - val_loss: 1.9102 - val_weighted_acc: 0.7020\n",
      "Epoch 51/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8806 - weighted_acc: 0.8143 - val_loss: 1.9093 - val_weighted_acc: 0.7040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.8752 - weighted_acc: 0.8071 - val_loss: 1.9083 - val_weighted_acc: 0.7060\n",
      "Epoch 53/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8777 - weighted_acc: 0.7500 - val_loss: 1.9073 - val_weighted_acc: 0.7060\n",
      "Epoch 54/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8720 - weighted_acc: 0.7929 - val_loss: 1.9063 - val_weighted_acc: 0.7040\n",
      "Epoch 55/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8699 - weighted_acc: 0.8500 - val_loss: 1.9053 - val_weighted_acc: 0.7060\n",
      "Epoch 56/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8695 - weighted_acc: 0.7857 - val_loss: 1.9044 - val_weighted_acc: 0.7040\n",
      "Epoch 57/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8692 - weighted_acc: 0.8143 - val_loss: 1.9034 - val_weighted_acc: 0.7020\n",
      "Epoch 58/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8694 - weighted_acc: 0.8429 - val_loss: 1.9024 - val_weighted_acc: 0.7100\n",
      "Epoch 59/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8670 - weighted_acc: 0.8143 - val_loss: 1.9015 - val_weighted_acc: 0.7100\n",
      "Epoch 60/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8648 - weighted_acc: 0.8000 - val_loss: 1.9005 - val_weighted_acc: 0.7060\n",
      "Epoch 61/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.8639 - weighted_acc: 0.8357 - val_loss: 1.8996 - val_weighted_acc: 0.7060\n",
      "Epoch 62/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8570 - weighted_acc: 0.8286 - val_loss: 1.8987 - val_weighted_acc: 0.7040\n",
      "Epoch 63/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8568 - weighted_acc: 0.8000 - val_loss: 1.8977 - val_weighted_acc: 0.7000\n",
      "Epoch 64/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8539 - weighted_acc: 0.8286 - val_loss: 1.8968 - val_weighted_acc: 0.7000\n",
      "Epoch 65/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8570 - weighted_acc: 0.8000 - val_loss: 1.8958 - val_weighted_acc: 0.7000\n",
      "Epoch 66/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8523 - weighted_acc: 0.7714 - val_loss: 1.8948 - val_weighted_acc: 0.7040\n",
      "Epoch 67/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8556 - weighted_acc: 0.8071 - val_loss: 1.8938 - val_weighted_acc: 0.6980\n",
      "Epoch 68/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8517 - weighted_acc: 0.8714 - val_loss: 1.8927 - val_weighted_acc: 0.6980\n",
      "Epoch 69/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.8484 - weighted_acc: 0.8429 - val_loss: 1.8916 - val_weighted_acc: 0.7000\n",
      "Epoch 70/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8449 - weighted_acc: 0.8143 - val_loss: 1.8905 - val_weighted_acc: 0.7020\n",
      "Epoch 71/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8377 - weighted_acc: 0.9143 - val_loss: 1.8894 - val_weighted_acc: 0.7100\n",
      "Epoch 72/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.8434 - weighted_acc: 0.8429 - val_loss: 1.8882 - val_weighted_acc: 0.7140\n",
      "Epoch 73/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.8385 - weighted_acc: 0.8500 - val_loss: 1.8869 - val_weighted_acc: 0.7160\n",
      "Epoch 74/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8367 - weighted_acc: 0.8643 - val_loss: 1.8857 - val_weighted_acc: 0.7260\n",
      "Epoch 75/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8332 - weighted_acc: 0.8357 - val_loss: 1.8844 - val_weighted_acc: 0.7300\n",
      "Epoch 76/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8325 - weighted_acc: 0.8571 - val_loss: 1.8832 - val_weighted_acc: 0.7280\n",
      "Epoch 77/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8249 - weighted_acc: 0.8500 - val_loss: 1.8820 - val_weighted_acc: 0.7320\n",
      "Epoch 78/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8261 - weighted_acc: 0.8500 - val_loss: 1.8808 - val_weighted_acc: 0.7320\n",
      "Epoch 79/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8262 - weighted_acc: 0.8214 - val_loss: 1.8796 - val_weighted_acc: 0.7300\n",
      "Epoch 80/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8191 - weighted_acc: 0.9000 - val_loss: 1.8784 - val_weighted_acc: 0.7300\n",
      "Epoch 81/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8179 - weighted_acc: 0.8714 - val_loss: 1.8773 - val_weighted_acc: 0.7280\n",
      "Epoch 82/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.8207 - weighted_acc: 0.8643 - val_loss: 1.8761 - val_weighted_acc: 0.7300\n",
      "Epoch 83/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.8181 - weighted_acc: 0.8643 - val_loss: 1.8749 - val_weighted_acc: 0.7260\n",
      "Epoch 84/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8126 - weighted_acc: 0.8714 - val_loss: 1.8739 - val_weighted_acc: 0.7260\n",
      "Epoch 85/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8143 - weighted_acc: 0.7714 - val_loss: 1.8728 - val_weighted_acc: 0.7220\n",
      "Epoch 86/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8107 - weighted_acc: 0.8500 - val_loss: 1.8717 - val_weighted_acc: 0.7220\n",
      "Epoch 87/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.8095 - weighted_acc: 0.8429 - val_loss: 1.8707 - val_weighted_acc: 0.7240\n",
      "Epoch 88/100\n",
      "2708/2708 [==============================] - 0s 11us/step - loss: 1.8068 - weighted_acc: 0.8500 - val_loss: 1.8696 - val_weighted_acc: 0.7240\n",
      "Epoch 89/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8039 - weighted_acc: 0.8500 - val_loss: 1.8686 - val_weighted_acc: 0.7260\n",
      "Epoch 90/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.8116 - weighted_acc: 0.8286 - val_loss: 1.8675 - val_weighted_acc: 0.7280\n",
      "Epoch 91/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.7970 - weighted_acc: 0.8643 - val_loss: 1.8664 - val_weighted_acc: 0.7280\n",
      "Epoch 92/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.7981 - weighted_acc: 0.8714 - val_loss: 1.8652 - val_weighted_acc: 0.7280\n",
      "Epoch 93/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.7949 - weighted_acc: 0.8500 - val_loss: 1.8640 - val_weighted_acc: 0.7260\n",
      "Epoch 94/100\n",
      "2708/2708 [==============================] - 0s 9us/step - loss: 1.7906 - weighted_acc: 0.8214 - val_loss: 1.8628 - val_weighted_acc: 0.7260\n",
      "Epoch 95/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.7893 - weighted_acc: 0.8000 - val_loss: 1.8615 - val_weighted_acc: 0.7260\n",
      "Epoch 96/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.7875 - weighted_acc: 0.8429 - val_loss: 1.8603 - val_weighted_acc: 0.7280\n",
      "Epoch 97/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.7811 - weighted_acc: 0.8357 - val_loss: 1.8589 - val_weighted_acc: 0.7260\n",
      "Epoch 98/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.7775 - weighted_acc: 0.8929 - val_loss: 1.8575 - val_weighted_acc: 0.7260\n",
      "Epoch 99/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.7777 - weighted_acc: 0.8500 - val_loss: 1.8561 - val_weighted_acc: 0.7300\n",
      "Epoch 100/100\n",
      "2708/2708 [==============================] - 0s 10us/step - loss: 1.7677 - weighted_acc: 0.8786 - val_loss: 1.8547 - val_weighted_acc: 0.7300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4dbfbbba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "validation_data = ([X, A], y_val, val_mask)\n",
    "model.fit([X, A],\n",
    "          y_train,\n",
    "          sample_weight=train_mask,\n",
    "          epochs=100,\n",
    "          batch_size=N,\n",
    "          validation_data=validation_data,\n",
    "          shuffle=False)  # Shuffling data means shuffling the whole graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708/2708 [==============================] - 0s 6us/step\n",
      "Done.\n",
      "Test loss: 1.8529187440872192\n",
      "Test accuracy: 0.7399999499320984\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "eval_results = model.evaluate([X, A],\n",
    "                              y_test,\n",
    "                              sample_weight=test_mask,\n",
    "                              batch_size=N)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*eval_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader:\n",
    "\n",
    "https://github.com/danielegrattarola/spektral/blob/master/spektral/datasets/qm9.py\n",
    "\n",
    "https://github.com/danielegrattarola/spektral/blob/master/examples/regression_molecules.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from spektral.datasets import qm9\n",
    "from spektral.layers import EdgeConditionedConv, GlobalAttentionPool\n",
    "from spektral.utils import label_to_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/133885 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading QM9 dataset.\n",
      "Reading SDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133885/133885 [00:43<00:00, 3060.38it/s]\n"
     ]
    }
   ],
   "source": [
    "adj, nf, ef, y = qm9.load_data(return_type='numpy',\n",
    "                               nf_keys='atomic_num',\n",
    "                               ef_keys='type',\n",
    "                               self_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.469],\n",
       "       [ 6.316],\n",
       "       [ 6.002],\n",
       "       ...,\n",
       "       [23.972],\n",
       "       [24.796],\n",
       "       [23.434]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y[['cv']].values  # Heat capacity at 298.15K\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "uniq_nf = np.unique(nf)\n",
    "nf = label_to_one_hot(nf, uniq_nf)\n",
    "uniq_ef = np.unique(ef)\n",
    "ef = label_to_one_hot(ef, uniq_ef)\n",
    "y_array_scaled = StandardScaler().fit_transform(y_array).reshape(-1, y_array.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "adj_train, adj_test, \\\n",
    "nf_train, nf_test,   \\\n",
    "ef_train, ef_test,   \\\n",
    "y_train, y_test = train_test_split(adj, nf, ef, y_array_scaled, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = nf.shape[-2]          # Number of nodes in the graphs\n",
    "F = nf.shape[-1]          # Node features dimensionality\n",
    "S = ef.shape[-1]          # Edge features dimensionality\n",
    "n_out = y_array.shape[-1]       # Dimensionality of the target\n",
    "learning_rate = 1e-3      # Learning rate for SGD\n",
    "epochs = 25               # Number of training epochs\n",
    "batch_size = 64           # Batch size\n",
    "es_patience = 5           # Patience fot early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "nf_in = Input(shape=(N, F))\n",
    "adj_in = Input(shape=(N, N))\n",
    "ef_in = Input(shape=(N, N, S))\n",
    "\n",
    "gc1 = EdgeConditionedConv(32, activation='relu')([nf_in, adj_in, ef_in])\n",
    "gc2 = EdgeConditionedConv(64, activation='relu')([gc1, adj_in, ef_in])\n",
    "pool = GlobalAttentionPool(128)(gc2)\n",
    "dense1 = Dense(128, activation='relu')(pool)\n",
    "\n",
    "output = Dense(n_out)(dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 29, 6)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 29, 29)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 29, 29, 4)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_conditioned_conv_5 (EdgeCo (None, 29, 32)       992         input_14[0][0]                   \n",
      "                                                                 input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conditioned_conv_6 (EdgeCo (None, 29, 64)       10304       edge_conditioned_conv_5[0][0]    \n",
      "                                                                 input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_attention_pool_3 (Global (None, 128)          16640       edge_conditioned_conv_6[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       global_attention_pool_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            129         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 44,577\n",
      "Trainable params: 44,577\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Model(inputs=[nf_in, adj_in, ef_in], outputs=output)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "es_callback = EarlyStopping(monitor='val_loss', patience=es_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120496, 29, 6), (120496, 29, 29), (120496, 29, 29, 4), (120496, 1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_train.shape, adj_train.shape, ef_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108446 samples, validate on 12050 samples\n",
      "Epoch 1/25\n",
      "108446/108446 [==============================] - 409s 4ms/step - loss: 0.0619 - val_loss: 0.0305\n",
      "Epoch 2/25\n",
      " 33088/108446 [========>.....................] - ETA: 4:33 - loss: 0.0344"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit([nf_train, adj_train, ef_train],\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
