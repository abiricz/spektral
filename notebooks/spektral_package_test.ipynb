{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from spektral.datasets import citation\n",
    "import spektral\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spektral.layers import GraphConv\n",
    "from spektral import utils\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source:\n",
    "https://danielegrattarola.github.io/spektral/getting-started/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n",
      "Pre-processing node features\n"
     ]
    }
   ],
   "source": [
    "data = spektral.datasets.citation.load_data('cora')\n",
    "A, X, y_train, y_val, y_test, train_mask, val_mask, test_mask = data\n",
    "\n",
    "N = A.shape[0]\n",
    "F = X.shape[-1]\n",
    "n_classes = y_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2708, 2708), (2708, 1433), (2708, 7), (2708, 7), (2708,), (2708,), (2708,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, X.shape, y_val.shape, y_test.shape, train_mask.shape, val_mask.shape, test_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abiricz/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/abiricz/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "X_in = Input(shape=(F, ))  # Input layer for X\n",
    "A_in = Input((N, ), sparse=True)  # Input layer for A\n",
    "\n",
    "graph_conv_1 = GraphConv(16, activation='relu')([X_in, A_in])\n",
    "dropout = Dropout(0.5)(graph_conv_1)\n",
    "graph_conv_2 = GraphConv(n_classes, activation='softmax')([dropout, A_in])\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, A_in], outputs=graph_conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = utils.localpooling_filter(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2708)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_1 (GraphConv)        (None, 16)           22944       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           graph_conv_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_2 (GraphConv)        (None, 7)            119         dropout_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,063\n",
      "Trainable params: 23,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abiricz/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2708 samples, validate on 2708 samples\n",
      "Epoch 1/100\n",
      "2708/2708 [==============================] - 1s 437us/step - loss: 1.9461 - weighted_acc: 0.1929 - val_loss: 1.9457 - val_weighted_acc: 0.1260\n",
      "Epoch 2/100\n",
      "2708/2708 [==============================] - 0s 13us/step - loss: 1.9453 - weighted_acc: 0.2429 - val_loss: 1.9451 - val_weighted_acc: 0.1540\n",
      "Epoch 3/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9444 - weighted_acc: 0.2714 - val_loss: 1.9445 - val_weighted_acc: 0.2100\n",
      "Epoch 4/100\n",
      "2708/2708 [==============================] - 0s 13us/step - loss: 1.9437 - weighted_acc: 0.2857 - val_loss: 1.9440 - val_weighted_acc: 0.2740\n",
      "Epoch 5/100\n",
      "2708/2708 [==============================] - 0s 13us/step - loss: 1.9430 - weighted_acc: 0.3429 - val_loss: 1.9435 - val_weighted_acc: 0.2900\n",
      "Epoch 6/100\n",
      "2708/2708 [==============================] - 0s 13us/step - loss: 1.9415 - weighted_acc: 0.3786 - val_loss: 1.9431 - val_weighted_acc: 0.3100\n",
      "Epoch 7/100\n",
      "2708/2708 [==============================] - 0s 13us/step - loss: 1.9405 - weighted_acc: 0.4214 - val_loss: 1.9426 - val_weighted_acc: 0.3440\n",
      "Epoch 8/100\n",
      "2708/2708 [==============================] - 0s 13us/step - loss: 1.9406 - weighted_acc: 0.4286 - val_loss: 1.9422 - val_weighted_acc: 0.3600\n",
      "Epoch 9/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.9393 - weighted_acc: 0.4357 - val_loss: 1.9418 - val_weighted_acc: 0.3500\n",
      "Epoch 10/100\n",
      "2708/2708 [==============================] - 0s 13us/step - loss: 1.9377 - weighted_acc: 0.4714 - val_loss: 1.9413 - val_weighted_acc: 0.3440\n",
      "Epoch 11/100\n",
      "2708/2708 [==============================] - 0s 22us/step - loss: 1.9368 - weighted_acc: 0.4429 - val_loss: 1.9409 - val_weighted_acc: 0.3580\n",
      "Epoch 12/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.9364 - weighted_acc: 0.3929 - val_loss: 1.9404 - val_weighted_acc: 0.3680\n",
      "Epoch 13/100\n",
      "2708/2708 [==============================] - 0s 19us/step - loss: 1.9344 - weighted_acc: 0.5286 - val_loss: 1.9399 - val_weighted_acc: 0.3860\n",
      "Epoch 14/100\n",
      "2708/2708 [==============================] - 0s 21us/step - loss: 1.9339 - weighted_acc: 0.5000 - val_loss: 1.9393 - val_weighted_acc: 0.3920\n",
      "Epoch 15/100\n",
      "2708/2708 [==============================] - 0s 16us/step - loss: 1.9321 - weighted_acc: 0.4857 - val_loss: 1.9387 - val_weighted_acc: 0.4020\n",
      "Epoch 16/100\n",
      "2708/2708 [==============================] - 0s 15us/step - loss: 1.9314 - weighted_acc: 0.4500 - val_loss: 1.9380 - val_weighted_acc: 0.4220\n",
      "Epoch 17/100\n",
      "2708/2708 [==============================] - 0s 16us/step - loss: 1.9299 - weighted_acc: 0.5071 - val_loss: 1.9373 - val_weighted_acc: 0.4360\n",
      "Epoch 18/100\n",
      "2708/2708 [==============================] - 0s 15us/step - loss: 1.9293 - weighted_acc: 0.4714 - val_loss: 1.9366 - val_weighted_acc: 0.4400\n",
      "Epoch 19/100\n",
      "2708/2708 [==============================] - 0s 14us/step - loss: 1.9285 - weighted_acc: 0.4857 - val_loss: 1.9359 - val_weighted_acc: 0.4540\n",
      "Epoch 20/100\n",
      "2708/2708 [==============================] - 0s 15us/step - loss: 1.9262 - weighted_acc: 0.5500 - val_loss: 1.9352 - val_weighted_acc: 0.4620\n",
      "Epoch 21/100\n",
      "2708/2708 [==============================] - 0s 24us/step - loss: 1.9249 - weighted_acc: 0.5071 - val_loss: 1.9345 - val_weighted_acc: 0.4780\n",
      "Epoch 22/100\n",
      "2708/2708 [==============================] - 0s 20us/step - loss: 1.9250 - weighted_acc: 0.5500 - val_loss: 1.9338 - val_weighted_acc: 0.4940\n",
      "Epoch 23/100\n",
      "2708/2708 [==============================] - 0s 24us/step - loss: 1.9215 - weighted_acc: 0.5714 - val_loss: 1.9331 - val_weighted_acc: 0.5080\n",
      "Epoch 24/100\n",
      "2708/2708 [==============================] - 0s 24us/step - loss: 1.9208 - weighted_acc: 0.6500 - val_loss: 1.9324 - val_weighted_acc: 0.5200\n",
      "Epoch 25/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.9187 - weighted_acc: 0.6214 - val_loss: 1.9317 - val_weighted_acc: 0.5220\n",
      "Epoch 26/100\n",
      "2708/2708 [==============================] - 0s 19us/step - loss: 1.9212 - weighted_acc: 0.6357 - val_loss: 1.9311 - val_weighted_acc: 0.5220\n",
      "Epoch 27/100\n",
      "2708/2708 [==============================] - 0s 18us/step - loss: 1.9169 - weighted_acc: 0.6214 - val_loss: 1.9304 - val_weighted_acc: 0.5420\n",
      "Epoch 28/100\n",
      "2708/2708 [==============================] - 0s 17us/step - loss: 1.9169 - weighted_acc: 0.6357 - val_loss: 1.9297 - val_weighted_acc: 0.5460\n",
      "Epoch 29/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.9128 - weighted_acc: 0.6857 - val_loss: 1.9291 - val_weighted_acc: 0.5560\n",
      "Epoch 30/100\n",
      "2708/2708 [==============================] - 0s 24us/step - loss: 1.9123 - weighted_acc: 0.7571 - val_loss: 1.9284 - val_weighted_acc: 0.5700\n",
      "Epoch 31/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.9115 - weighted_acc: 0.7000 - val_loss: 1.9277 - val_weighted_acc: 0.5720\n",
      "Epoch 32/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.9102 - weighted_acc: 0.7286 - val_loss: 1.9271 - val_weighted_acc: 0.5720\n",
      "Epoch 33/100\n",
      "2708/2708 [==============================] - 0s 19us/step - loss: 1.9113 - weighted_acc: 0.7071 - val_loss: 1.9264 - val_weighted_acc: 0.5720\n",
      "Epoch 34/100\n",
      "2708/2708 [==============================] - 0s 17us/step - loss: 1.9076 - weighted_acc: 0.7143 - val_loss: 1.9258 - val_weighted_acc: 0.5780\n",
      "Epoch 35/100\n",
      "2708/2708 [==============================] - 0s 15us/step - loss: 1.9055 - weighted_acc: 0.6857 - val_loss: 1.9251 - val_weighted_acc: 0.5760\n",
      "Epoch 36/100\n",
      "2708/2708 [==============================] - 0s 14us/step - loss: 1.9032 - weighted_acc: 0.7143 - val_loss: 1.9244 - val_weighted_acc: 0.5700\n",
      "Epoch 37/100\n",
      "2708/2708 [==============================] - 0s 21us/step - loss: 1.9033 - weighted_acc: 0.7500 - val_loss: 1.9237 - val_weighted_acc: 0.5620\n",
      "Epoch 38/100\n",
      "2708/2708 [==============================] - 0s 14us/step - loss: 1.9005 - weighted_acc: 0.7429 - val_loss: 1.9229 - val_weighted_acc: 0.5600\n",
      "Epoch 39/100\n",
      "2708/2708 [==============================] - 0s 14us/step - loss: 1.8986 - weighted_acc: 0.7143 - val_loss: 1.9222 - val_weighted_acc: 0.5540\n",
      "Epoch 40/100\n",
      "2708/2708 [==============================] - 0s 15us/step - loss: 1.8984 - weighted_acc: 0.7143 - val_loss: 1.9215 - val_weighted_acc: 0.5540\n",
      "Epoch 41/100\n",
      "2708/2708 [==============================] - 0s 19us/step - loss: 1.8968 - weighted_acc: 0.7143 - val_loss: 1.9208 - val_weighted_acc: 0.5560\n",
      "Epoch 42/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.8962 - weighted_acc: 0.6786 - val_loss: 1.9200 - val_weighted_acc: 0.5560\n",
      "Epoch 43/100\n",
      "2708/2708 [==============================] - 0s 24us/step - loss: 1.8936 - weighted_acc: 0.7429 - val_loss: 1.9192 - val_weighted_acc: 0.5600\n",
      "Epoch 44/100\n",
      "2708/2708 [==============================] - 0s 20us/step - loss: 1.8917 - weighted_acc: 0.8071 - val_loss: 1.9183 - val_weighted_acc: 0.5700\n",
      "Epoch 45/100\n",
      "2708/2708 [==============================] - 0s 20us/step - loss: 1.8885 - weighted_acc: 0.7571 - val_loss: 1.9175 - val_weighted_acc: 0.5720\n",
      "Epoch 46/100\n",
      "2708/2708 [==============================] - 0s 18us/step - loss: 1.8853 - weighted_acc: 0.8000 - val_loss: 1.9167 - val_weighted_acc: 0.5700\n",
      "Epoch 47/100\n",
      "2708/2708 [==============================] - 0s 16us/step - loss: 1.8868 - weighted_acc: 0.7429 - val_loss: 1.9159 - val_weighted_acc: 0.5720\n",
      "Epoch 48/100\n",
      "2708/2708 [==============================] - 0s 15us/step - loss: 1.8827 - weighted_acc: 0.7286 - val_loss: 1.9151 - val_weighted_acc: 0.5800\n",
      "Epoch 49/100\n",
      "2708/2708 [==============================] - 0s 14us/step - loss: 1.8808 - weighted_acc: 0.7714 - val_loss: 1.9142 - val_weighted_acc: 0.5800\n",
      "Epoch 50/100\n",
      "2708/2708 [==============================] - 0s 24us/step - loss: 1.8818 - weighted_acc: 0.7500 - val_loss: 1.9134 - val_weighted_acc: 0.5820\n",
      "Epoch 51/100\n",
      "2708/2708 [==============================] - 0s 15us/step - loss: 1.8820 - weighted_acc: 0.7714 - val_loss: 1.9126 - val_weighted_acc: 0.5840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "2708/2708 [==============================] - 0s 13us/step - loss: 1.8801 - weighted_acc: 0.7571 - val_loss: 1.9118 - val_weighted_acc: 0.5900\n",
      "Epoch 53/100\n",
      "2708/2708 [==============================] - 0s 19us/step - loss: 1.8767 - weighted_acc: 0.7857 - val_loss: 1.9109 - val_weighted_acc: 0.5900\n",
      "Epoch 54/100\n",
      "2708/2708 [==============================] - 0s 22us/step - loss: 1.8731 - weighted_acc: 0.7857 - val_loss: 1.9100 - val_weighted_acc: 0.5980\n",
      "Epoch 55/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.8732 - weighted_acc: 0.7714 - val_loss: 1.9092 - val_weighted_acc: 0.5980\n",
      "Epoch 56/100\n",
      "2708/2708 [==============================] - 0s 19us/step - loss: 1.8696 - weighted_acc: 0.7643 - val_loss: 1.9083 - val_weighted_acc: 0.6000\n",
      "Epoch 57/100\n",
      "2708/2708 [==============================] - 0s 17us/step - loss: 1.8719 - weighted_acc: 0.7714 - val_loss: 1.9074 - val_weighted_acc: 0.6040\n",
      "Epoch 58/100\n",
      "2708/2708 [==============================] - 0s 15us/step - loss: 1.8673 - weighted_acc: 0.8214 - val_loss: 1.9065 - val_weighted_acc: 0.6020\n",
      "Epoch 59/100\n",
      "2708/2708 [==============================] - 0s 15us/step - loss: 1.8677 - weighted_acc: 0.7929 - val_loss: 1.9055 - val_weighted_acc: 0.6100\n",
      "Epoch 60/100\n",
      "2708/2708 [==============================] - 0s 14us/step - loss: 1.8650 - weighted_acc: 0.8286 - val_loss: 1.9045 - val_weighted_acc: 0.6120\n",
      "Epoch 61/100\n",
      "2708/2708 [==============================] - 0s 12us/step - loss: 1.8635 - weighted_acc: 0.7357 - val_loss: 1.9035 - val_weighted_acc: 0.6200\n",
      "Epoch 62/100\n",
      "2708/2708 [==============================] - 0s 22us/step - loss: 1.8569 - weighted_acc: 0.8214 - val_loss: 1.9025 - val_weighted_acc: 0.6200\n",
      "Epoch 63/100\n",
      "2708/2708 [==============================] - 0s 16us/step - loss: 1.8570 - weighted_acc: 0.7929 - val_loss: 1.9015 - val_weighted_acc: 0.6100\n",
      "Epoch 64/100\n",
      "2708/2708 [==============================] - 0s 13us/step - loss: 1.8519 - weighted_acc: 0.8000 - val_loss: 1.9004 - val_weighted_acc: 0.6100\n",
      "Epoch 65/100\n",
      "2708/2708 [==============================] - 0s 21us/step - loss: 1.8493 - weighted_acc: 0.8500 - val_loss: 1.8994 - val_weighted_acc: 0.6100\n",
      "Epoch 66/100\n",
      "2708/2708 [==============================] - 0s 20us/step - loss: 1.8494 - weighted_acc: 0.8286 - val_loss: 1.8984 - val_weighted_acc: 0.6100\n",
      "Epoch 67/100\n",
      "2708/2708 [==============================] - 0s 17us/step - loss: 1.8507 - weighted_acc: 0.7500 - val_loss: 1.8974 - val_weighted_acc: 0.6080\n",
      "Epoch 68/100\n",
      "2708/2708 [==============================] - 0s 24us/step - loss: 1.8464 - weighted_acc: 0.8357 - val_loss: 1.8963 - val_weighted_acc: 0.6080\n",
      "Epoch 69/100\n",
      "2708/2708 [==============================] - 0s 24us/step - loss: 1.8450 - weighted_acc: 0.8571 - val_loss: 1.8953 - val_weighted_acc: 0.6080\n",
      "Epoch 70/100\n",
      "2708/2708 [==============================] - 0s 22us/step - loss: 1.8453 - weighted_acc: 0.8000 - val_loss: 1.8943 - val_weighted_acc: 0.6080\n",
      "Epoch 71/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.8430 - weighted_acc: 0.8071 - val_loss: 1.8934 - val_weighted_acc: 0.6080\n",
      "Epoch 72/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.8421 - weighted_acc: 0.7857 - val_loss: 1.8925 - val_weighted_acc: 0.6060\n",
      "Epoch 73/100\n",
      "2708/2708 [==============================] - 0s 24us/step - loss: 1.8347 - weighted_acc: 0.7929 - val_loss: 1.8916 - val_weighted_acc: 0.6100\n",
      "Epoch 74/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.8370 - weighted_acc: 0.7929 - val_loss: 1.8906 - val_weighted_acc: 0.6080\n",
      "Epoch 75/100\n",
      "2708/2708 [==============================] - 0s 21us/step - loss: 1.8371 - weighted_acc: 0.8071 - val_loss: 1.8897 - val_weighted_acc: 0.6120\n",
      "Epoch 76/100\n",
      "2708/2708 [==============================] - 0s 17us/step - loss: 1.8343 - weighted_acc: 0.8500 - val_loss: 1.8888 - val_weighted_acc: 0.6160\n",
      "Epoch 77/100\n",
      "2708/2708 [==============================] - 0s 17us/step - loss: 1.8290 - weighted_acc: 0.8357 - val_loss: 1.8878 - val_weighted_acc: 0.6120\n",
      "Epoch 78/100\n",
      "2708/2708 [==============================] - 0s 17us/step - loss: 1.8318 - weighted_acc: 0.7929 - val_loss: 1.8869 - val_weighted_acc: 0.6140\n",
      "Epoch 79/100\n",
      "2708/2708 [==============================] - 0s 22us/step - loss: 1.8260 - weighted_acc: 0.7786 - val_loss: 1.8859 - val_weighted_acc: 0.6160\n",
      "Epoch 80/100\n",
      "2708/2708 [==============================] - 0s 22us/step - loss: 1.8244 - weighted_acc: 0.7929 - val_loss: 1.8849 - val_weighted_acc: 0.6140\n",
      "Epoch 81/100\n",
      "2708/2708 [==============================] - 0s 19us/step - loss: 1.8245 - weighted_acc: 0.8000 - val_loss: 1.8838 - val_weighted_acc: 0.6160\n",
      "Epoch 82/100\n",
      "2708/2708 [==============================] - 0s 24us/step - loss: 1.8199 - weighted_acc: 0.8000 - val_loss: 1.8827 - val_weighted_acc: 0.6160\n",
      "Epoch 83/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.8136 - weighted_acc: 0.8143 - val_loss: 1.8816 - val_weighted_acc: 0.6180\n",
      "Epoch 84/100\n",
      "2708/2708 [==============================] - 0s 19us/step - loss: 1.8109 - weighted_acc: 0.7929 - val_loss: 1.8804 - val_weighted_acc: 0.6220\n",
      "Epoch 85/100\n",
      "2708/2708 [==============================] - 0s 17us/step - loss: 1.8094 - weighted_acc: 0.8071 - val_loss: 1.8793 - val_weighted_acc: 0.6180\n",
      "Epoch 86/100\n",
      "2708/2708 [==============================] - 0s 16us/step - loss: 1.8071 - weighted_acc: 0.7857 - val_loss: 1.8782 - val_weighted_acc: 0.6180\n",
      "Epoch 87/100\n",
      "2708/2708 [==============================] - 0s 22us/step - loss: 1.8053 - weighted_acc: 0.8286 - val_loss: 1.8771 - val_weighted_acc: 0.6200\n",
      "Epoch 88/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.8123 - weighted_acc: 0.8214 - val_loss: 1.8760 - val_weighted_acc: 0.6220\n",
      "Epoch 89/100\n",
      "2708/2708 [==============================] - 0s 19us/step - loss: 1.8066 - weighted_acc: 0.7786 - val_loss: 1.8748 - val_weighted_acc: 0.6280\n",
      "Epoch 90/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.8057 - weighted_acc: 0.8143 - val_loss: 1.8736 - val_weighted_acc: 0.6280\n",
      "Epoch 91/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.7989 - weighted_acc: 0.7929 - val_loss: 1.8724 - val_weighted_acc: 0.6260\n",
      "Epoch 92/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.7936 - weighted_acc: 0.8143 - val_loss: 1.8712 - val_weighted_acc: 0.6320\n",
      "Epoch 93/100\n",
      "2708/2708 [==============================] - 0s 22us/step - loss: 1.7919 - weighted_acc: 0.8286 - val_loss: 1.8701 - val_weighted_acc: 0.6360\n",
      "Epoch 94/100\n",
      "2708/2708 [==============================] - 0s 18us/step - loss: 1.7955 - weighted_acc: 0.8071 - val_loss: 1.8689 - val_weighted_acc: 0.6380\n",
      "Epoch 95/100\n",
      "2708/2708 [==============================] - 0s 16us/step - loss: 1.7798 - weighted_acc: 0.8357 - val_loss: 1.8677 - val_weighted_acc: 0.6320\n",
      "Epoch 96/100\n",
      "2708/2708 [==============================] - 0s 15us/step - loss: 1.7896 - weighted_acc: 0.8000 - val_loss: 1.8665 - val_weighted_acc: 0.6300\n",
      "Epoch 97/100\n",
      "2708/2708 [==============================] - 0s 22us/step - loss: 1.7904 - weighted_acc: 0.7929 - val_loss: 1.8653 - val_weighted_acc: 0.6300\n",
      "Epoch 98/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.7941 - weighted_acc: 0.8071 - val_loss: 1.8641 - val_weighted_acc: 0.6360\n",
      "Epoch 99/100\n",
      "2708/2708 [==============================] - 0s 20us/step - loss: 1.7798 - weighted_acc: 0.8000 - val_loss: 1.8629 - val_weighted_acc: 0.6360\n",
      "Epoch 100/100\n",
      "2708/2708 [==============================] - 0s 23us/step - loss: 1.7871 - weighted_acc: 0.8214 - val_loss: 1.8617 - val_weighted_acc: 0.6400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f976f654390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "validation_data = ([X, A], y_val, val_mask)\n",
    "model.fit([X, A],\n",
    "          y_train,\n",
    "          sample_weight=train_mask,\n",
    "          epochs=100,\n",
    "          batch_size=N,\n",
    "          validation_data=validation_data,\n",
    "          shuffle=False)  # Shuffling data means shuffling the whole graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708/2708 [==============================] - 0s 5us/step\n",
      "Done.\n",
      "Test loss: 1.8558011054992676\n",
      "Test accuracy: 0.6709999442100525\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "eval_results = model.evaluate([X, A],\n",
    "                              y_test,\n",
    "                              sample_weight=test_mask,\n",
    "                              batch_size=N)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*eval_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader:\n",
    "\n",
    "https://github.com/danielegrattarola/spektral/blob/master/spektral/datasets/qm9.py\n",
    "\n",
    "https://github.com/danielegrattarola/spektral/blob/master/examples/regression_molecules.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from spektral.datasets import qm9\n",
    "from spektral.layers import EdgeConditionedConv, GlobalAttentionPool\n",
    "from spektral.utils import label_to_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading QM9 dataset.\n",
      "Reading SDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133885/133885 [00:29<00:00, 4502.93it/s]\n"
     ]
    }
   ],
   "source": [
    "adj, nf, ef, y = qm9.load_data(return_type='numpy',\n",
    "                               nf_keys='atomic_num',\n",
    "                               ef_keys='type',\n",
    "                               self_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.469],\n",
       "       [ 6.316],\n",
       "       [ 6.002],\n",
       "       ...,\n",
       "       [23.972],\n",
       "       [24.796],\n",
       "       [23.434]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y[['cv']].values # Heat capacity at 298.15K\n",
    "#y_array = y.iloc[:, 1:].values\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "uniq_nf = np.unique(nf)\n",
    "nf = label_to_one_hot(nf, uniq_nf)\n",
    "uniq_ef = np.unique(ef)\n",
    "ef = label_to_one_hot(ef, uniq_ef)\n",
    "y_array_scaled = StandardScaler().fit_transform(y_array).reshape(-1, y_array.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "adj_train, adj_test, \\\n",
    "nf_train, nf_test,   \\\n",
    "ef_train, ef_test,   \\\n",
    "y_train, y_test = train_test_split(adj, nf, ef, y_array_scaled, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = nf.shape[-2]          # Number of nodes in the graphs\n",
    "F = nf.shape[-1]          # Node features dimensionality\n",
    "S = ef.shape[-1]          # Edge features dimensionality\n",
    "n_out = y_array.shape[-1]       # Dimensionality of the target\n",
    "learning_rate = 1e-3      # Learning rate for SGD\n",
    "epochs = 25               # Number of training epochs\n",
    "batch_size = 64           # Batch size\n",
    "es_patience = 5           # Patience fot early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abiricz/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "nf_in = Input(shape=(N, F))\n",
    "adj_in = Input(shape=(N, N))\n",
    "ef_in = Input(shape=(N, N, S))\n",
    "\n",
    "gc1 = EdgeConditionedConv(32, activation='relu')([nf_in, adj_in, ef_in])\n",
    "gc2 = EdgeConditionedConv(64, activation='relu')([gc1, adj_in, ef_in])\n",
    "pool = GlobalAttentionPool(128)(gc2)\n",
    "dense1 = Dense(128, activation='relu')(pool)\n",
    "\n",
    "output = Dense(n_out)(dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 29, 6)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 29, 29)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 29, 29, 4)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_conditioned_conv_1 (EdgeCo (None, 29, 32)       992         input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "edge_conditioned_conv_2 (EdgeCo (None, 29, 64)       10304       edge_conditioned_conv_1[0][0]    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_attention_pool_1 (Global (None, 128)          16640       edge_conditioned_conv_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       global_attention_pool_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 44,577\n",
      "Trainable params: 44,577\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Model(inputs=[nf_in, adj_in, ef_in], outputs=output)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "es_callback = EarlyStopping(monitor='val_loss', patience=es_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120496, 29, 6), (120496, 29, 29), (120496, 29, 29, 4), (120496, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf_train.shape, adj_train.shape, ef_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abiricz/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 108446 samples, validate on 12050 samples\n",
      "Epoch 1/25\n",
      "108446/108446 [==============================] - 110s 1ms/step - loss: 0.0616 - val_loss: 0.0425\n",
      "Epoch 2/25\n",
      "108446/108446 [==============================] - 108s 998us/step - loss: 0.0350 - val_loss: 0.0320\n",
      "Epoch 3/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0317 - val_loss: 0.0265\n",
      "Epoch 4/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0297 - val_loss: 0.0273\n",
      "Epoch 5/25\n",
      "108446/108446 [==============================] - 108s 998us/step - loss: 0.0273 - val_loss: 0.0224\n",
      "Epoch 6/25\n",
      "108446/108446 [==============================] - 108s 1000us/step - loss: 0.0256 - val_loss: 0.0304\n",
      "Epoch 7/25\n",
      "108446/108446 [==============================] - 108s 1000us/step - loss: 0.0246 - val_loss: 0.0246\n",
      "Epoch 8/25\n",
      "108446/108446 [==============================] - 108s 1000us/step - loss: 0.0228 - val_loss: 0.0249\n",
      "Epoch 9/25\n",
      "108446/108446 [==============================] - 108s 1000us/step - loss: 0.0221 - val_loss: 0.0200\n",
      "Epoch 10/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0209 - val_loss: 0.0182\n",
      "Epoch 11/25\n",
      "108446/108446 [==============================] - 108s 1000us/step - loss: 0.0202 - val_loss: 0.0194\n",
      "Epoch 12/25\n",
      "108446/108446 [==============================] - 108s 1000us/step - loss: 0.0196 - val_loss: 0.0184\n",
      "Epoch 13/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0187 - val_loss: 0.0252\n",
      "Epoch 14/25\n",
      "108446/108446 [==============================] - 108s 998us/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 15/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 16/25\n",
      "108446/108446 [==============================] - 108s 998us/step - loss: 0.0173 - val_loss: 0.0154\n",
      "Epoch 17/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0171 - val_loss: 0.0156\n",
      "Epoch 18/25\n",
      "108446/108446 [==============================] - 108s 1000us/step - loss: 0.0165 - val_loss: 0.0159\n",
      "Epoch 19/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0163 - val_loss: 0.0144\n",
      "Epoch 20/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0156 - val_loss: 0.0140\n",
      "Epoch 21/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0155 - val_loss: 0.0138\n",
      "Epoch 22/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0150 - val_loss: 0.0141\n",
      "Epoch 23/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 24/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0145 - val_loss: 0.0131\n",
      "Epoch 25/25\n",
      "108446/108446 [==============================] - 108s 999us/step - loss: 0.0142 - val_loss: 0.0149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda23d94048>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit([nf_train, adj_train, ef_train],\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model.\n",
      "13389/13389 [==============================] - 7s 501us/step\n",
      "Done.\n",
      "Test loss: 0.01427250599306511\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print('Evaluating model.')\n",
    "eval_results = model.evaluate([nf_test, adj_test, ef_test],\n",
    "                              y_test,\n",
    "                              batch_size=batch_size)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}'.format(eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Actual')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot predictions\n",
    "preds = model.predict([nf_test, adj_test, ef_test])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(preds, y_test, alpha=0.3)\n",
    "plt.plot(range(-6, 6), range(-6, 6))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "#plt.savefig('pred_v_true.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11946759377970118"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt( np.sum( (preds - y_test)**2 ) / preds.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
